{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron Machine Learning Project\n",
    "### By Matthew Adkins\n",
    "\n",
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, a significant amount of typically confidential information entered into the public record, including tens of thousands of emails and detailed financial data for top executives.\n",
    "\n",
    "In this project I will apply my knowledge of machine learning and build a person of interest identifier. The identifier will harness financial and email data that was made public.\n",
    "\n",
    "There are four critical steps in this project:\n",
    "\n",
    "1. Enron Dataset Cleaning\n",
    "2. Feature Creation and Processing\n",
    "3. Applying a Learning Algorithm\n",
    "4. Validating the Accuracy of the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Enron Dataset\n",
    "\n",
    "\n",
    "We'll start by loading the loading up the dataset and then we'll take a peak at what we can use to start creating an effective identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Owner\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from tester import dump_classifier_and_data\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "\n",
    "from feature_format import featureFormat\n",
    "from feature_format import targetFeatureSplit\n",
    "\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = [\"poi\", \"poi_per_to_msg\", \"poi_per_from_msg\",'bonus', 'shared_receipt_with_poi']\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data loaded in to our programs let's take a look at the structure.\n",
    "\n",
    "We'll see how many executives are included in the set as well as what kind of financial and email data we have on each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total executives:  146\n"
     ]
    }
   ],
   "source": [
    "print \"Total executives: \", len(data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features:  21\n"
     ]
    }
   ],
   "source": [
    "print \"Total features: \", len(data_dict['SKILLING JEFFREY K'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of features: \n",
      "\n",
      "['salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'email_address', 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "print \"Here is the list of features: \" + \"\\n\" + \"\\n\",str(data_dict['SKILLING JEFFREY K'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'salary': 365788, 'to_messages': 807, 'deferral_payments': 'NaN', 'total_payments': 1061827, 'exercised_stock_options': 'NaN', 'bonus': 600000, 'restricted_stock': 585062, 'shared_receipt_with_poi': 702, 'restricted_stock_deferred': 'NaN', 'total_stock_value': 585062, 'expenses': 94299, 'loan_advances': 'NaN', 'from_messages': 29, 'other': 1740, 'from_this_person_to_poi': 1, 'poi': False, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 'NaN', 'email_address': 'mark.metts@enron.com', 'from_poi_to_this_person': 38}\n"
     ]
    }
   ],
   "source": [
    "print data_dict['METTS MARK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that there are 146 executives in the data set with numerous amounts of information on each. While we are looking at the features in this data we should think about what features would be helpful in creating new features from. \n",
    "\n",
    "Originally I made two features options_per_stock and bonus_per_salary. The logic was that person's of interest (poi) would sell their equity in the company and pay themselves outsized bonuses. However, I could not obtain a high accuracy with the correct precision and recall parameters. So, in this iteration of the project we will look at two new features:\n",
    "\n",
    "1. poi_per_to_msg\n",
    "2. poi_per_from_msg\n",
    "\n",
    "\n",
    "These two features look at an individuals to and from messages and what fraction of each where to known poi's. Since the the financial behaviors were harder to pin down let's see if we have better luck using email behaviors.\n",
    "\n",
    "Let's take a look at some of the known poi's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is the list of 18 POI's: \n",
      "\n",
      "['HANNON KEVIN P', 'COLWELL WESLEY', 'RIEKER PAULA H', 'KOPPER MICHAEL J', 'SHELBY REX', 'DELAINEY DAVID W', 'LAY KENNETH L', 'BOWEN JR RAYMOND M', 'BELDEN TIMOTHY N', 'FASTOW ANDREW S', 'CALGER CHRISTOPHER F', 'RICE KENNETH D', 'SKILLING JEFFREY K', 'YEAGER F SCOTT', 'HIRKO JOSEPH', 'KOENIG MARK E', 'CAUSEY RICHARD A', 'GLISAN JR BEN F']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "poi = []\n",
    "\n",
    "for data in data_dict:\n",
    "    if data_dict[data]['poi'] == 1:\n",
    "        count += 1\n",
    "        poi.append(data)\n",
    "print \" Here is the list of \" + str(count) + \" POI's: \" + \"\\n\"\n",
    "print poi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll look at any missing data in our features, ie NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing Values for Each Feature:\n",
      "salary: 51\n",
      "to_messages: 60\n",
      "deferral_payments: 107\n",
      "total_payments: 21\n",
      "exercised_stock_options: 44\n",
      "bonus: 64\n",
      "restricted_stock: 36\n",
      "shared_receipt_with_poi: 60\n",
      "restricted_stock_deferred: 128\n",
      "total_stock_value: 20\n",
      "expenses: 51\n",
      "loan_advances: 142\n",
      "from_messages: 60\n",
      "other: 53\n",
      "from_this_person_to_poi: 60\n",
      "poi: 0\n",
      "director_fees: 129\n",
      "deferred_income: 97\n",
      "long_term_incentive: 80\n",
      "email_address: 35\n",
      "from_poi_to_this_person: 60\n"
     ]
    }
   ],
   "source": [
    "missing_value = {}\n",
    "all_features = data_dict['LOCKHART EUGENE E'].keys()\n",
    "people = data_dict.keys()\n",
    "for feature in all_features:\n",
    "    missing_value[feature]=0\n",
    "for person in people:\n",
    "    records = 0\n",
    "    for feature in all_features:\n",
    "        if data_dict[person][feature] == 'NaN':\n",
    "            missing_value[feature] += 1\n",
    "        else:\n",
    "            records +=1\n",
    "        \n",
    "print('Number of Missing Values for Each Feature:')\n",
    "for feature in all_features:\n",
    "    print(\"%s: %d\" % (feature, missing_value[feature]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by the table above we have quite a lot of NaN values in our data set. Converting them to zero will help fill in the gaps in the data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now before we get too far let's look for any obvious outliers. We'll plot and see if we can visually see any of the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAERCAYAAACU1LsdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGoaCJKnx/wHyW/O0vTHMbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbd4b2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person with the highest paid salary is:  TOTAL\n",
      "Highest paid salary:  26704229\n"
     ]
    }
   ],
   "source": [
    "### Task 2: Remove outliers\n",
    "\n",
    "#Plot showing outlier\n",
    "features=['bonus', 'salary']\n",
    "data = featureFormat(data_dict, features)\n",
    "for point in data:\n",
    "    salary=point[0]\n",
    "    bonus=point[1]\n",
    "    plt.scatter(salary,bonus)\n",
    "plt.xlabel('salary')\n",
    "plt.ylabel('bonus')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "salaries = []\n",
    "\n",
    "for i in data_dict:\n",
    "    if type(data_dict[i]['salary'])== int:\n",
    "        salaries.append(data_dict[i]['salary'])\n",
    "for i in data_dict:    \n",
    "    if data_dict[i]['salary'] == max(salaries):\n",
    "        print \"The person with the highest paid salary is: \", i\n",
    "print \"Highest paid salary: \", str(max(salaries))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After plotting the graph we can clearly see an outlier. This outlier happens to be the total salary for the whole dataset. So, since it is not an actual person we will remove it leaving us with 145 real Enron executives.\n",
    "\n",
    "While we are removing the outliers we will also remove any NaN's from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAEKCAYAAABQRFHsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEYmVEpGIiMRKiUhERGKlRCQiIrH6/4lw3FIdlKZsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6b02588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### remove any outliers before proceeding further\n",
    "features = [\"salary\", \"bonus\"]\n",
    "data_dict.pop('TOTAL', 0)\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "### remove NAN's from dataset\n",
    "outliers = []\n",
    "for key in data_dict:\n",
    "    val = data_dict[key]['salary']\n",
    "    if val == 'NaN':\n",
    "        continue\n",
    "    outliers.append((key, int(val)))\n",
    "\n",
    "\n",
    "#plot after removing the outlier\n",
    "for point in data:\n",
    "    salary=point[0]\n",
    "    bonus=point[1]\n",
    "    plt.scatter(salary,bonus)\n",
    "plt.xlabel('salary')\n",
    "plt.ylabel('bonus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the outlier we can see the graph is much easier to interpret. There does seem to be a few outliers but these may also be our poi's. Let's take a look at the top four salaries and determine if any are known poi's.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 4 highest salary holders are:  [('SKILLING JEFFREY K', 1111258), ('LAY KENNETH L', 1072321), ('FREVERT MARK A', 1060932), ('PICKERING MARK R', 655037)]\n"
     ]
    }
   ],
   "source": [
    "highest_sal = sorted(outliers,key =lambda x:x[1], reverse=True)[:4]\n",
    "\n",
    "\n",
    "print \"The top 4 highest salary holders are: \", highest_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are POI's among our top 4 outliers: \n",
      "SKILLING JEFFREY K\n",
      "LAY KENNETH L\n"
     ]
    }
   ],
   "source": [
    "#determine if they are poi's\n",
    "print \"The following are POI's among our top 4 outliers: \"\n",
    "for person in highest_sal:\n",
    "    if data_dict[person[0]]['poi'] == 1:\n",
    "        print person[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that some of the outliers are indeed POI's and thus we won't need any further cleaning of the data. So, with the data cleaned to where we need it we can now move on to feature processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Processing\n",
    "\n",
    "Now that we have finished cleaning and removing outliers from the we can start creating a predicative algorithm to find POI's. We'll start but seeing how well the original features can predict a potential POI. After we discover a baseline of accuracy we will try to improve it by creating new features of our own.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.706896551724\n",
      "Precision:   0.153846153846\n",
      "Recall:   0.25\n",
      "Decision Tree run time:   0.016 s\n"
     ]
    }
   ],
   "source": [
    "#data_dict = pickle.load(open(\"../final_project/final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "features_list = ['poi','salary', 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'director_fees', 'deferred_income', 'long_term_incentive']\n",
    "\n",
    "data = featureFormat(data_dict, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "#split data into traing and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size= 0.4, random_state = 42)\n",
    "\n",
    "#utlize decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "t0 = time()\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc= accuracy_score(labels_test, pred)\n",
    "print 'Accuracy:  ' , str(acc)\n",
    "print 'Precision:  ', precision_score(labels_test, pred)\n",
    "print 'Recall:  ', recall_score(labels_test, pred)\n",
    "print 'Decision Tree run time:  ', round(time()-t0, 3), 's'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the given features we obtain an accuracy of about 71%. Next we will make a list that shows the importance of each feature. With this we can decide which features are worth keeping around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Feature salary (0.303225638483)\n",
      "2 Feature from_poi_to_this_person (0.212288925439)\n",
      "3 Feature from_this_person_to_poi (0.182731050113)\n",
      "4 Feature to_messages (0.169736842105)\n",
      "5 Feature deferral_payments (0.111271929825)\n",
      "6 Feature total_payments (0.0207456140351)\n",
      "7 Feature exercised_stock_options (0.0)\n",
      "8 Feature bonus (0.0)\n",
      "9 Feature restricted_stock (0.0)\n",
      "10 Feature shared_receipt_with_poi (0.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "importance = clf.feature_importances_\n",
    "index = np.argsort(importance)[::-1]\n",
    "\n",
    "for i in range(10):\n",
    "    print \"{} Feature {} ({})\".format(i+1, features_list[i+1], importance[index[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After establishing a ranking we can see that there are several features that contribute very little to our accuracy. We will be leaving these features out from further calculations.\n",
    "\n",
    "Next let's create our new features and see if we can improve on the accuracy measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "\n",
    "### create new features\n",
    "### poi_per_to_msg = (from_poi_to_this_person)/(to_messages)\n",
    "### poi_per_from_msg = (from_this_person_to_poi)/(from_messages)\n",
    "\n",
    "def dict_to_list(key,normalizer):\n",
    "    new_list=[]\n",
    "\n",
    "    for i in data_dict:\n",
    "        if data_dict[i][key]==\"NaN\" or data_dict[i][normalizer]==\"NaN\":\n",
    "            new_list.append(0.)\n",
    "        elif data_dict[i][key]>=0:\n",
    "            new_list.append(float(data_dict[i][key])/float(data_dict[i][normalizer]))\n",
    "    return new_list\n",
    "\n",
    "### creating new list of features\n",
    "poi_per_to_msg=dict_to_list(\"from_poi_to_this_person\",\"to_messages\")\n",
    "poi_per_from_msg=dict_to_list(\"from_this_person_to_poi\",\"from_messages\")\n",
    "\n",
    "### insert new features into data_dict\n",
    "count=0\n",
    "for i in data_dict:\n",
    "    data_dict[i][\"poi_per_to_msg\"]=poi_per_to_msg[count]\n",
    "    data_dict[i][\"poi_per_from_msg\"]=poi_per_from_msg[count]\n",
    "    count +=1\n",
    "\n",
    "#test\n",
    "#print data_dict['SKILLING JEFFREY K']['poi_per_to_msg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Applying Learning Algorithms\n",
    "\n",
    "\n",
    "Now that we created our new features that we want to explore lets take a look at how accurate our creations are at identifying poi's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.733333333333\n",
      "Precision:   0.5\n",
      "Recall:   0.5\n"
     ]
    }
   ],
   "source": [
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "features_list = ['poi','poi_per_to_msg','poi_per_from_msg','salary', 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'from_messages', 'director_fees', 'deferred_income', 'long_term_incentive']\n",
    "\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "\n",
    "## split into labels and features (this line assumes that the first\n",
    "### feature in the array is the label, which is why \"poi\" must always\n",
    "### be first in features_list\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "#Provided to give you a starting point. Try a variety of classifiers.\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "#t0 = time()\n",
    "clf =DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print 'Accuracy:  ' + str(acc)\n",
    "print 'Precision:  ', precision_score(labels_test, pred)\n",
    "print 'Recall:  ', recall_score(labels_test, pred)\n",
    "#print 'Run Time:  ', round(time()-t0, 3), 's'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding our new features it appears that the precision has increased but the accuracy and recall haven't gotten to a desirable value. Let's recheck the features using SelectKBest. This should help narrow down the features a bit better than relying on my own intuition.\n",
    "\n",
    "SelectKBest takes in all of the features and will return the top most valuable features, in this case we asked for the top 12 features. This will help us further our accuracy, precision, and recall ratings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best features to use are:  ['poi', 'poi_per_to_msg', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'director_fees', 'deferred_income']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "data_dict = pickle.load(open(\"../final_project/final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "features_list = ['poi','salary', 'poi_per_to_msg', 'poi_per_from_msg', 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'director_fees', 'deferred_income', 'long_term_incentive']\n",
    "\n",
    "data= featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "selector = SelectKBest(k=12)\n",
    "selectedFeatures = selector.fit(features, labels)\n",
    "features_names = [features_list[i] for i in selectedFeatures.get_support(indices=True)]\n",
    "\n",
    "print 'The best features to use are: ', features_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above we now have a list of the top 12 features to use. It looks like that one of our created features 'poi_per_from_msg' did not make the top 12. However, I decided to keep it as I want to see if we can achieve credible accuracy scores using both of the new features.\n",
    "\n",
    "\n",
    "Now that we have a better idea of what features should be used let's see if this achieves the imporvements that we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6\n",
      "Precision:   0.25\n",
      "Recall:   0.25\n"
     ]
    }
   ],
   "source": [
    "data_dict = pickle.load(open(\"../final_project/final_project_dataset.pkl\", \"r\") )\n",
    "\n",
    "features_list = ['poi', 'poi_per_to_msg', 'poi_per_from_msg', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'restricted_stock_deferred','total_stock_value','expenses', 'director_fees', 'deferred_income']\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "clf =DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print 'Accuracy:  ' + str(acc)\n",
    "print 'Precision:  ', precision_score(labels_test, pred)\n",
    "print 'Recall:  ', recall_score(labels_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the recommended features our accuracy, precision, and recall scores were more or less flat. I also decided to leave my feature 'poi_per_from_msg' in the feature list as a way to see it's affect on other algorithms. So let's see if any other algorithm's will improve on our scores.\n",
    "\n",
    "\n",
    "\n",
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.844827586207\n",
      "Precision:   0.4\n",
      "Recall:   0.25\n"
     ]
    }
   ],
   "source": [
    "features_list = ['poi', 'poi_per_to_msg', 'poi_per_from_msg', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'restricted_stock_deferred','total_stock_value','expenses', 'director_fees', 'deferred_income']\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.4, random_state = 42)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "\n",
    "print 'Accuracy:  ', str(acc)\n",
    "print 'Precision:  ' ,precision_score(labels_test, pred)\n",
    "print 'Recall:  ' ,recall_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Adaboost classifier the accuracy increased by our precision and recall scores fell. This could be a sign of underfitting as the Adaboost algorithm is favoring misidentifying POI's, which is a small part of the dataset, over misidentifying non-POI's, the greater part of the dataset. Because of this let's see if RandomForest will be a better solution versus our DecisionTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.879310344828\n",
      "Precision:   1.0\n",
      "Recall:   0.125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "\n",
    "print 'Accuracy:  ', str(acc)\n",
    "print 'Precision:  ', precision_score(labels_test, pred)\n",
    "print 'Recall:  ', recall_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the RandomForestClassifier the accuracy came out as significantly better than Adaboost but Recall fell greatly while precision is 1.0. This could be a sign that the RandomForest classifier is overfitting and not giving us accurate measures. Given this observation it appears that DecisionTree is the best algorithm for our data_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validating and Algorithm Tuning\n",
    "\n",
    "Here we will take DecisionTree algor## 4. Validating and Algorithm Tuning\n",
    "\n",
    "Here we will take DecisionTree algorithm and tune it to see if we improve on our already superior results. Using GridSearchCV as a guide we should be able to find the ideal settings for DecisionTree.\n",
    "\n",
    " This is important as tuning the parameters allows us to finely tune the DecisionTree from or towards overfitting of the data. We can also change a parameter like max_depth to determine with features have a chance of becoming a decision node.\n",
    " \n",
    " This algorithm was validated by using cross-valdiation, precision and recall scores. \n",
    " \n",
    "It is important to note that, though we have been using accuracy throughout the program it should be avoided in our final validation. This is because the number of POIs is much smaller (18 in our test set, that the total number of executives (145 after cleaning the outlier) in our dataset thus giving our dataset a large imbalance. This creates a problem for machine learning algorithms where the algorithm underfits the data. Without proper tuning the algorithm will miss a large number of our POI's but will correctly identify regular executives as being non-POI's. This leads to a smaller number of total mistakes and gives us a higher accuracy rating. However, in our case this is problematic because we would rather capture more of the POI's at the cost of misidentifying non-POI's. So putting our accuracy score on the back burner and tune to increase our Precision and Recall scores we will capture more of our POI's.\n",
    "\n",
    "\n",
    "Now, let's tune our algorithm and see if we improve on our results from above. Using GridSearchCV as a guide we should be able to find the ideal settings for DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ideal tuned settings for DecisionTree is: \n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features=3, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "data = my_dataset\n",
    "features_list = ['poi', 'poi_per_to_msg', 'poi_per_from_msg', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'restricted_stock_deferred','total_stock_value','expenses', 'director_fees', 'deferred_income']\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.4, random_state = 42)\n",
    "\n",
    "\n",
    "parameters = {'min_samples_split': [2,3,4,5,6,7,8], 'max_depth': [1,2,3,4,5,6,7,8], 'max_features': range(3,10)}\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), parameters)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "\n",
    "print 'The ideal tuned settings for DecisionTree is: '\n",
    "print clf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearchCV we were able to find the ideal parameters for our DecisionTree. \n",
    "\n",
    "\n",
    "### More on validation\n",
    "The next step is to pass it through our final validation in which we will split the data into a training set and a testing set. The training set allows us to develop the algorithm while the test set tells us how well the algorithm will preform when applied to the full data set. It's important to know that we do not train the data on the test. This is because we would receive an accuracy of 100% but in reality the algorithm would have been poorly trained. \n",
    "\n",
    "With that said we used the StratifiedShuffledSplit from the test_classifier function found in test.py. This function works well with small and unbalanced datasets such as the one we are currently working on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = my_dataset\n",
    "features_list = ['poi', 'poi_per_to_msg', 'poi_per_from_msg', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'restricted_stock_deferred','total_stock_value','expenses', 'director_fees', 'deferred_income']\n",
    "\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "from tester import test_classifier\n",
    "\n",
    "test_classifier(clf, my_dataset, features_list)\n",
    "\n",
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Even after running GridSearchCV it still took some experimentation to find the right mixture of settings to achieve a the desired Precision and Recall score of better than 0.3. It's important to keep in mind that when viewing these scores 1.0 is the best and 0.0 is the worst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Interpretating our precision an recall values helps us determine how well our program is at identifying POI's from other executives. Precision measures false positives or how many executives would be falsely identified as POI's. Given our value of 0.4 this means that 60% of our identified POI's are false alarms. \n",
    "\n",
    "Our other measure recall measures false negatives or how many POI's would be misidentified as regular executives. Given our value of .57 this means that we have captured 57% of the time we captured one of the POI's but at the price of misidentifying regular executives. This could be a case of overfitting the data and thus capturing too many points that don't belong in the POI group.\n",
    "\n",
    "As mentioned in the beginning of this paper I attempted to use financial data but the precision and recall was far below our threshold value of 0.3. This means that using the financial parameters I created was very inefficient. With this said further looking into the actual words used in the emails to/from the POI's could help keep our 33% of innocent executives safe from prosecution. Using a data set of keywords used between executives and the POI's would make our algorithm even more accurate.\n",
    "\n",
    "Notes on feature scaling:\n",
    "\n",
    "In this case we did not use feature scaling, meaning we did not scale down/up a feature that has more/less data points in relationship to the other features. This is because DecisionTree does not need feature scaling as it splits based on each feature independently. Thus, scaling the features would be inappropiate for our chosen algorithm. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
